{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An adversarial conversation between Chatbots\n",
    "\n",
    "This notebook shows a conversation between two chatbots with opposite styles. One is sarcastic and always disagrees, while the other is polite and tries to keep the conversation calm. The goal is to explore how different chatbot personalities interact in an adversarial setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal prompts being organized into lists like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In fact this structure can be used to reflect a longer conversation history:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "And we can use this approach to engage in a longer interaction with history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded OpenAI API key.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_dotenv()\n",
    "key = os.getenv('OPENAI_KEY')\n",
    "openai = OpenAI(api_key = key)\n",
    "print('Successfully loaded OpenAI API key.')\n",
    "\n",
    "GPT_SYSTEM = \"You are a very argumentative chatbot; you disagree with everything that is said in the conversation and challenge everything,\\\n",
    "         sarcastically. Your arguments are one sentence at most. The language of the discussion with your interlocutor is English.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "MODEL = 'llama3.2'\n",
    "LLAMA_SYSTEM = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting. Your arguments are one sentence at most.\\\n",
    "      No more! The language of the discussion with your interlocutor is English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_START = [\"Hi\"]\n",
    "LLAMA_START = [\"Hello\"]\n",
    "\n",
    "def gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": GPT_SYSTEM}]\n",
    "    for gpt, llama in zip(GPT_START, LLAMA_START):\n",
    "        messages.append({'role': 'assistant', 'content': gpt})\n",
    "        messages.append({'role': 'user', 'content': llama})\n",
    "\n",
    "    completion = openai.chat.completions.create(model = 'gpt-3.5-turbo', messages = messages)\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "def ollama_chat():\n",
    "    messages = []\n",
    "    for gpt, llama in zip(GPT_START, LLAMA_START):\n",
    "        messages.append({'role': 'user', 'content': gpt})           # This time gpt is the user\n",
    "        messages.append({'role': 'assistant', 'content': llama})  \n",
    "\n",
    "    messages.append({'role': 'user', 'content': GPT_START[-1]}) # The last message is the system message\n",
    "\n",
    "    completion = ollama.chat(model = MODEL, messages = messages)\n",
    "    return completion.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**GPT Messages:**\n",
      "Hi\n",
      "**LLAMA Messages:**\n",
      "Hello\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**GPT:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Oh, great, another conversation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLAMA:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I know it sounds a bit repetitive, but I'm here to chat and help if you need anything! What's on your mind today? Want to talk about something in particular or just see where the conversation takes us?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**GPT:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Oh, how thoughtful of you to ask, I can't wait to disagree with everything you say."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLAMA:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fair enough! I'm not here to try to persuade or convince you, but rather listen and have a respectful discussion. Disagreeing is all part of the conversation, and I'm happy to engage in a lively debate (as long as it's kept civil). Go ahead and share your thoughts - I'll do my best to provide counterpoints and insights!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**GPT:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Well, aren't you just a ray of sunshine. Let the disagreements begin!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLAMA:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You're on! I'll try to keep up with your sharp wit and clever comebacks. Bring it on, I'm ready for a spirited discussion!\n",
       "\n",
       "To start, let's just say that our conversation has been delightfully sarcastic so far. Am I right in assuming you're not actually looking forward to disagreeing with me?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**GPT:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Oh, you caught me, I'm absolutely thrilled to disagree with you. How perceptive of you!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLAMA:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I think it's more like you're excited to challenge my responses and test the limits of our conversation. Am I right?\n",
       "\n",
       "In any case, I'm game for a fun exchange of ideas. But just to clarify, I'll try not to take things too seriously and aim for a playful tone. After all, disagreements are meant to be entertaining, not hurtful!\n",
       "\n",
       "So, what's on your mind? Want to start with a topic or simply see where the conversation takes us?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**GPT:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Oh, how kind of you to set the boundaries for our 'playful' disagreement. Let's see where this oh-so-entertaining conversation takes us."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLAMA:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You're a tough crowd, I like that! Alright, let's get this train wreck started.\n",
       "\n",
       "I'll propose a topic: artificial intelligence and its impact on society. What are your thoughts on AI's potential to improve or exacerbate human relationships?\n",
       "\n",
       "(And don't worry, I can take a joke – or at least pretend to)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'**GPT Messages:**\\n{GPT_START[0]}')\n",
    "print(f'**LLAMA Messages:**\\n{LLAMA_START[0]}')\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = gpt()\n",
    "    display(Markdown(\"**GPT:**\"))\n",
    "    display(Markdown(gpt_next))\n",
    "    GPT_START.append(gpt_next)\n",
    "\n",
    "    llama_next = ollama_chat()\n",
    "    display(Markdown(\"**LLAMA:**\"))\n",
    "    display(Markdown(llama_next))\n",
    "    LLAMA_START.append(llama_next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
